{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "mybkvtykyixv8rjd0h7y"
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "cellId": "fvkha16iisngatwl256058",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: --use-feature=2020-resolver no longer has any effect, since it is now the default dependency resolver in pip. This will become an error in pip 21.0.\u001b[0m\n",
      "Collecting catalyst\n",
      "  Using cached catalyst-20.11-py2.py3-none-any.whl (489 kB)\n",
      "Collecting deprecation\n",
      "  Using cached deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting GitPython>=3.1.1\n",
      "  Using cached GitPython-3.1.11-py3-none-any.whl (159 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.5-py3-none-any.whl (63 kB)\n",
      "Collecting ipython\n",
      "  Using cached ipython-7.13.0-py3-none-any.whl (780 kB)\n",
      "Collecting backcall\n",
      "  Using cached backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting decorator\n",
      "  Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Collecting jedi>=0.10\n",
      "  Using cached jedi-0.17.2-py2.py3-none-any.whl (1.4 MB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.3.3-cp37-cp37m-manylinux1_x86_64.whl (11.6 MB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.3.1-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
      "Collecting numpy>=1.16.4\n",
      "  Using cached numpy-1.19.4-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
      "Collecting packaging\n",
      "  Using cached packaging-20.8-py2.py3-none-any.whl (39 kB)\n",
      "Collecting pandas>=0.22\n",
      "  Using cached pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\n",
      "Collecting parso<0.8.0,>=0.7.0\n",
      "  Using cached parso-0.7.1-py2.py3-none-any.whl (109 kB)\n",
      "Collecting pexpect\n",
      "  Using cached pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
      "Collecting pickleshare\n",
      "  Using cached pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
      "Collecting pillow>=6.2.0\n",
      "  Using cached Pillow-8.0.1-cp37-cp37m-manylinux1_x86_64.whl (2.2 MB)\n",
      "Collecting plotly>=4.1.0\n",
      "  Using cached plotly-4.14.1-py2.py3-none-any.whl (13.2 MB)\n",
      "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
      "  Using cached prompt_toolkit-3.0.8-py3-none-any.whl (355 kB)\n",
      "Collecting ptyprocess>=0.5\n",
      "  Using cached ptyprocess-0.6.0-py2.py3-none-any.whl (39 kB)\n",
      "Collecting pygments\n",
      "  Using cached Pygments-2.7.3-py3-none-any.whl (950 kB)\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3\n",
      "  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Collecting python-dateutil>=2.1\n",
      "  Using cached python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting pytz>=2017.2\n",
      "  Using cached pytz-2020.4-py2.py3-none-any.whl (509 kB)\n",
      "Collecting PyYAML\n",
      "  Using cached PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl\n",
      "Collecting retrying>=1.3.3\n",
      "  Using cached retrying-1.3.3-py3-none-any.whl\n",
      "Collecting scikit-learn>=0.20\n",
      "  Using cached scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
      "Collecting joblib>=0.11\n",
      "  Using cached joblib-1.0.0-py3-none-any.whl (302 kB)\n",
      "Collecting scipy>=0.19.1\n",
      "  Using cached scipy-1.5.4-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
      "Collecting setuptools>=18.5\n",
      "  Using cached setuptools-51.0.0-py3-none-any.whl (785 kB)\n",
      "Collecting six\n",
      "  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting smmap<4,>=3.0.1\n",
      "  Using cached smmap-3.0.4-py2.py3-none-any.whl (25 kB)\n",
      "Collecting tensorboard>=1.14.0\n",
      "  Using cached tensorboard-2.4.0-py3-none-any.whl (10.6 MB)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Using cached google_auth-1.24.0-py2.py3-none-any.whl (114 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached cachetools-4.2.0-py3-none-any.whl (12 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.2-py2.py3-none-any.whl (18 kB)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Using cached grpcio-1.34.0-cp37-cp37m-manylinux2014_x86_64.whl (3.9 MB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.3-py3-none-any.whl (96 kB)\n",
      "Collecting importlib-metadata\n",
      "  Using cached importlib_metadata-3.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting protobuf>=3.6.0\n",
      "  Using cached protobuf-3.14.0-cp37-cp37m-manylinux1_x86_64.whl (1.0 MB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2020.12.5-py2.py3-none-any.whl (147 kB)\n",
      "Collecting chardet<5,>=3.0.2\n",
      "  Using cached chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Using cached idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.6-py3-none-any.whl (47 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n",
      "Collecting tensorboardX\n",
      "  Using cached tensorboardX-2.1-py2.py3-none-any.whl (308 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting torch>=1.1.0\n",
      "  Using cached torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n",
      "Collecting tqdm>=4.33.0\n",
      "  Using cached tqdm-4.54.1-py2.py3-none-any.whl (69 kB)\n",
      "Collecting traitlets>=4.2\n",
      "  Using cached traitlets-5.0.5-py3-none-any.whl (100 kB)\n",
      "Collecting ipython-genutils\n",
      "  Using cached ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting typing-extensions>=3.6.4\n",
      "  Using cached typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.2-py2.py3-none-any.whl (136 kB)\n",
      "Collecting wcwidth\n",
      "  Using cached wcwidth-0.2.5-py2.py3-none-any.whl (30 kB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Using cached Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting wheel>=0.26\n",
      "  Using cached wheel-0.36.2-py2.py3-none-any.whl (35 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.4.0-py3-none-any.whl (5.2 kB)\n",
      "Installing collected packages: urllib3, pyasn1, idna, chardet, certifi, zipp, typing-extensions, six, setuptools, rsa, requests, pyasn1-modules, oauthlib, cachetools, wcwidth, smmap, requests-oauthlib, pyparsing, ptyprocess, parso, numpy, ipython-genutils, importlib-metadata, google-auth, wheel, werkzeug, traitlets, threadpoolctl, tensorboard-plugin-wit, scipy, retrying, pytz, python-dateutil, pygments, protobuf, prompt-toolkit, pillow, pickleshare, pexpect, packaging, markdown, kiwisolver, joblib, jedi, grpcio, google-auth-oauthlib, gitdb, decorator, cycler, backcall, absl-py, tqdm, torch, tensorboardX, tensorboard, scikit-learn, PyYAML, plotly, pandas, matplotlib, ipython, GitPython, deprecation, catalyst\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.7.0 requires torch==1.6.0, but you have torch 1.7.1 which is incompatible.\n",
      "tensorflow 1.15.0 requires tensorboard<1.16.0,>=1.15.0, but you have tensorboard 2.4.0 which is incompatible.\n",
      "tensorflow-metadata 0.25.0 requires absl-py<0.11,>=0.9, but you have absl-py 0.11.0 which is incompatible.\n",
      "tensorflow-gpu 1.15.0 requires tensorboard<1.16.0,>=1.15.0, but you have tensorboard 2.4.0 which is incompatible.\n",
      "moto 1.3.14 requires idna<2.9,>=2.5, but you have idna 2.10 which is incompatible.\n",
      "mmdet 2.3.0rc0+c6b5ca2 requires Pillow<=6.2.2, but you have pillow 8.0.1 which is incompatible.\n",
      "mmdet 2.3.0rc0+c6b5ca2 requires torch==1.6.0, but you have torch 1.7.1 which is incompatible.\n",
      "kaggle 1.5.8 requires urllib3<1.25,>=1.21.1, but you have urllib3 1.26.2 which is incompatible.\n",
      "enot-utils 1.0.2 requires torch==1.6.0, but you have torch 1.7.1 which is incompatible.\n",
      "cloud-ml 0.0.1 requires requests<=2.25.0,>=2.22.0, but you have requests 2.25.1 which is incompatible.\n",
      "cloud-ml 0.0.1 requires tqdm<=4.53.0,>=4.45.0, but you have tqdm 4.54.1 which is incompatible.\n",
      "botocore 1.15.49 requires urllib3<1.26,>=1.20; python_version != \"3.4\", but you have urllib3 1.26.2 which is incompatible.\n",
      "ml-kernel 0.0.1 requires requests<=2.25.0,>=2.22.0, but you have requests 2.25.1 which is incompatible.\n",
      "ml-kernel 0.0.1 requires setuptools<=50.3.2, but you have setuptools 51.0.0 which is incompatible.\u001b[0m\n",
      "Successfully installed GitPython-3.1.11 PyYAML-5.3.1 absl-py-0.11.0 backcall-0.2.0 cachetools-4.2.0 catalyst-20.11 certifi-2020.12.5 chardet-4.0.0 cycler-0.10.0 decorator-4.4.2 deprecation-2.1.0 gitdb-4.0.5 google-auth-1.24.0 google-auth-oauthlib-0.4.2 grpcio-1.34.0 idna-2.10 importlib-metadata-3.3.0 ipython-7.13.0 ipython-genutils-0.2.0 jedi-0.17.2 joblib-1.0.0 kiwisolver-1.3.1 markdown-3.3.3 matplotlib-3.3.3 numpy-1.19.4 oauthlib-3.1.0 packaging-20.8 pandas-1.1.5 parso-0.7.1 pexpect-4.8.0 pickleshare-0.7.5 pillow-8.0.1 plotly-4.14.1 prompt-toolkit-3.0.8 protobuf-3.14.0 ptyprocess-0.6.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pygments-2.7.3 pyparsing-2.4.7 python-dateutil-2.8.1 pytz-2020.4 requests-2.25.1 requests-oauthlib-1.3.0 retrying-1.3.3 rsa-4.6 scikit-learn-0.23.2 scipy-1.5.4 setuptools-51.0.0 six-1.15.0 smmap-3.0.4 tensorboard-2.4.0 tensorboard-plugin-wit-1.7.0 tensorboardX-2.1 threadpoolctl-2.1.0 torch-1.7.1 tqdm-4.54.1 traitlets-5.0.5 typing-extensions-3.7.4.3 urllib3-1.26.2 wcwidth-0.2.5 werkzeug-1.0.1 wheel-0.36.2 zipp-3.4.0\n",
      "\u001b[33mWARNING: --use-feature=2020-resolver no longer has any effect, since it is now the default dependency resolver in pip. This will become an error in pip 21.0.\u001b[0m\n",
      "Collecting catalyst\n",
      "  Using cached catalyst-20.11-py2.py3-none-any.whl (489 kB)\n",
      "Collecting deprecation\n",
      "  Using cached deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting GitPython>=3.1.1\n",
      "  Using cached GitPython-3.1.11-py3-none-any.whl (159 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.5-py3-none-any.whl (63 kB)\n",
      "Collecting ipython\n",
      "  Using cached ipython-7.13.0-py3-none-any.whl (780 kB)\n",
      "Collecting backcall\n",
      "  Using cached backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting decorator\n",
      "  Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Collecting jedi>=0.10\n",
      "  Using cached jedi-0.17.2-py2.py3-none-any.whl (1.4 MB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.3.3-cp37-cp37m-manylinux1_x86_64.whl (11.6 MB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.3.1-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
      "Collecting numpy>=1.16.4\n",
      "  Using cached numpy-1.19.4-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
      "Collecting packaging\n",
      "  Using cached packaging-20.8-py2.py3-none-any.whl (39 kB)\n",
      "Collecting pandas>=0.22\n",
      "  Using cached pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\n",
      "Collecting parso<0.8.0,>=0.7.0\n",
      "  Using cached parso-0.7.1-py2.py3-none-any.whl (109 kB)\n",
      "Collecting pexpect\n",
      "  Using cached pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
      "Collecting pickleshare\n",
      "  Using cached pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
      "Collecting pillow>=6.2.0\n",
      "  Using cached Pillow-8.0.1-cp37-cp37m-manylinux1_x86_64.whl (2.2 MB)\n",
      "Collecting plotly>=4.1.0\n",
      "  Using cached plotly-4.14.1-py2.py3-none-any.whl (13.2 MB)\n",
      "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
      "  Using cached prompt_toolkit-3.0.8-py3-none-any.whl (355 kB)\n",
      "Collecting ptyprocess>=0.5\n",
      "  Using cached ptyprocess-0.6.0-py2.py3-none-any.whl (39 kB)\n",
      "Collecting pygments\n",
      "  Using cached Pygments-2.7.3-py3-none-any.whl (950 kB)\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3\n",
      "  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Collecting python-dateutil>=2.1\n",
      "  Using cached python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting pytz>=2017.2\n",
      "  Using cached pytz-2020.4-py2.py3-none-any.whl (509 kB)\n",
      "Collecting PyYAML\n",
      "  Using cached PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl\n",
      "Collecting retrying>=1.3.3\n",
      "  Using cached retrying-1.3.3-py3-none-any.whl\n",
      "Collecting scikit-learn>=0.20\n",
      "  Using cached scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
      "Collecting joblib>=0.11\n",
      "  Using cached joblib-1.0.0-py3-none-any.whl (302 kB)\n",
      "Collecting scipy>=0.19.1\n",
      "  Using cached scipy-1.5.4-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
      "Collecting setuptools>=18.5\n",
      "  Using cached setuptools-51.0.0-py3-none-any.whl (785 kB)\n",
      "Collecting six\n",
      "  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting smmap<4,>=3.0.1\n",
      "  Using cached smmap-3.0.4-py2.py3-none-any.whl (25 kB)\n",
      "Collecting tensorboard>=1.14.0\n",
      "  Using cached tensorboard-2.4.0-py3-none-any.whl (10.6 MB)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Using cached google_auth-1.24.0-py2.py3-none-any.whl (114 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached cachetools-4.2.0-py3-none-any.whl (12 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.2-py2.py3-none-any.whl (18 kB)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Using cached grpcio-1.34.0-cp37-cp37m-manylinux2014_x86_64.whl (3.9 MB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.3-py3-none-any.whl (96 kB)\n",
      "Collecting importlib-metadata\n",
      "  Using cached importlib_metadata-3.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting protobuf>=3.6.0\n",
      "  Using cached protobuf-3.14.0-cp37-cp37m-manylinux1_x86_64.whl (1.0 MB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2020.12.5-py2.py3-none-any.whl (147 kB)\n",
      "Collecting chardet<5,>=3.0.2\n",
      "  Using cached chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Using cached idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.6-py3-none-any.whl (47 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n",
      "Collecting tensorboardX\n",
      "  Using cached tensorboardX-2.1-py2.py3-none-any.whl (308 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting torch>=1.1.0\n",
      "  Using cached torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n",
      "Collecting tqdm>=4.33.0\n",
      "  Using cached tqdm-4.54.1-py2.py3-none-any.whl (69 kB)\n",
      "Collecting traitlets>=4.2\n",
      "  Using cached traitlets-5.0.5-py3-none-any.whl (100 kB)\n",
      "Collecting ipython-genutils\n",
      "  Using cached ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting typing-extensions>=3.6.4\n",
      "  Using cached typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.2-py2.py3-none-any.whl (136 kB)\n",
      "Collecting wcwidth\n",
      "  Using cached wcwidth-0.2.5-py2.py3-none-any.whl (30 kB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Using cached Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting wheel>=0.26\n",
      "  Using cached wheel-0.36.2-py2.py3-none-any.whl (35 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.4.0-py3-none-any.whl (5.2 kB)\n",
      "Installing collected packages: urllib3, pyasn1, idna, chardet, certifi, zipp, typing-extensions, six, setuptools, rsa, requests, pyasn1-modules, oauthlib, cachetools, wcwidth, smmap, requests-oauthlib, pyparsing, ptyprocess, parso, numpy, ipython-genutils, importlib-metadata, google-auth, wheel, werkzeug, traitlets, threadpoolctl, tensorboard-plugin-wit, scipy, retrying, pytz, python-dateutil, pygments, protobuf, prompt-toolkit, pillow, pickleshare, pexpect, packaging, markdown, kiwisolver, joblib, jedi, grpcio, google-auth-oauthlib, gitdb, decorator, cycler, backcall, absl-py, tqdm, torch, tensorboardX, tensorboard, scikit-learn, PyYAML, plotly, pandas, matplotlib, ipython, GitPython, deprecation, catalyst\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.7.0 requires torch==1.6.0, but you have torch 1.7.1 which is incompatible.\n",
      "tensorflow 1.15.0 requires tensorboard<1.16.0,>=1.15.0, but you have tensorboard 2.4.0 which is incompatible.\n",
      "tensorflow-metadata 0.25.0 requires absl-py<0.11,>=0.9, but you have absl-py 0.11.0 which is incompatible.\n",
      "tensorflow-gpu 1.15.0 requires tensorboard<1.16.0,>=1.15.0, but you have tensorboard 2.4.0 which is incompatible.\n",
      "moto 1.3.14 requires idna<2.9,>=2.5, but you have idna 2.10 which is incompatible.\n",
      "mmdet 2.3.0rc0+c6b5ca2 requires Pillow<=6.2.2, but you have pillow 8.0.1 which is incompatible.\n",
      "mmdet 2.3.0rc0+c6b5ca2 requires torch==1.6.0, but you have torch 1.7.1 which is incompatible.\n",
      "kaggle 1.5.8 requires urllib3<1.25,>=1.21.1, but you have urllib3 1.26.2 which is incompatible.\n",
      "enot-utils 1.0.2 requires torch==1.6.0, but you have torch 1.7.1 which is incompatible.\n",
      "cloud-ml 0.0.1 requires requests<=2.25.0,>=2.22.0, but you have requests 2.25.1 which is incompatible.\n",
      "cloud-ml 0.0.1 requires tqdm<=4.53.0,>=4.45.0, but you have tqdm 4.54.1 which is incompatible.\n",
      "botocore 1.15.49 requires urllib3<1.26,>=1.20; python_version != \"3.4\", but you have urllib3 1.26.2 which is incompatible.\n",
      "ml-kernel 0.0.1 requires requests<=2.25.0,>=2.22.0, but you have requests 2.25.1 which is incompatible.\n",
      "ml-kernel 0.0.1 requires setuptools<=50.3.2, but you have setuptools 51.0.0 which is incompatible.\u001b[0m\n",
      "Successfully installed GitPython-3.1.11 PyYAML-5.3.1 absl-py-0.11.0 backcall-0.2.0 cachetools-4.2.0 catalyst-20.11 certifi-2020.12.5 chardet-4.0.0 cycler-0.10.0 decorator-4.4.2 deprecation-2.1.0 gitdb-4.0.5 google-auth-1.24.0 google-auth-oauthlib-0.4.2 grpcio-1.34.0 idna-2.10 importlib-metadata-3.3.0 ipython-7.13.0 ipython-genutils-0.2.0 jedi-0.17.2 joblib-1.0.0 kiwisolver-1.3.1 markdown-3.3.3 matplotlib-3.3.3 numpy-1.19.4 oauthlib-3.1.0 packaging-20.8 pandas-1.1.5 parso-0.7.1 pexpect-4.8.0 pickleshare-0.7.5 pillow-8.0.1 plotly-4.14.1 prompt-toolkit-3.0.8 protobuf-3.14.0 ptyprocess-0.6.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pygments-2.7.3 pyparsing-2.4.7 python-dateutil-2.8.1 pytz-2020.4 requests-2.25.1 requests-oauthlib-1.3.0 retrying-1.3.3 rsa-4.6 scikit-learn-0.23.2 scipy-1.5.4 setuptools-51.0.0 six-1.15.0 smmap-3.0.4 tensorboard-2.4.0 tensorboard-plugin-wit-1.7.0 tensorboardX-2.1 threadpoolctl-2.1.0 torch-1.7.1 tqdm-4.54.1 traitlets-5.0.5 typing-extensions-3.7.4.3 urllib3-1.26.2 wcwidth-0.2.5 werkzeug-1.0.1 wheel-0.36.2 zipp-3.4.0\n",
      "\u001b[33mWARNING: You are using pip version 20.3; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:588: UserWarning: The following variables cannot be serialized: test_dataset, test_loader, tokenizer, train_dataset, train_loader\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "# %pip install transformers\n",
    "# %pip install tokenizers\n",
    "# %pip install youtokentome\n",
    "%pip install -U catalyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellId": "o1vgc67mus8me4x31bk24"
   },
   "outputs": [],
   "source": [
    "from string import ascii_letters\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import requests\n",
    "import random\n",
    "import shutil\n",
    "from typing import List\n",
    "from IPython.display import Audio\n",
    "\n",
    "# from midi2audio import FluidSynth\n",
    "# import music21\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import BertConfig, EncoderDecoderConfig, EncoderDecoderModel\n",
    "import youtokentome as yttm\n",
    "from catalyst import dl, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "s6xwx9dalxallfp26vz5tn"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "cellId": "z6kodhqzabziphc2o3nto"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting : 100%|██████████| 46/46 [00:07<00:00,  6.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# sound_font_zip = download_file('https://storage.yandexcloud.net/hackathon-2020/GeneralUser%20GS%201.471.zip', local_filename='GeneralUser_GS_1.471.zip')\n",
    "unzip(sound_font_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "cellId": "kr57ynt1w71gs3j0n65xm"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting : 100%|██████████| 364009/364009 [26:21<00:00, 230.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# trainset_path = download_file('https://storage.yandexcloud.net/hackathon-2020/trainset.zip', local_filename='trainset.zip')\n",
    "unzip(trainset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "cellId": "btm1rdtgetiybnsk0fxqxn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting : 100%|██████████| 20407/20407 [01:19<00:00, 255.69it/s]\n"
     ]
    }
   ],
   "source": [
    "# testset_path = download_file('https://storage.yandexcloud.net/hackathon-2020/testset.zip', local_filename='testset.zip')\n",
    "unzip(testset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cellId": "icbgvwbv3uq8lqeddly2g"
   },
   "outputs": [],
   "source": [
    "train_paths = collect_children(Path('trainset/abc'))[:128]\n",
    "# test_paths = collect_children(Path('testset/abc'))[:128]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "dgkzvrf585i1z97e3gv7u"
   },
   "source": [
    "## Load data into RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cellId": "m7mcfvce34c7sy3hor3wsk"
   },
   "outputs": [],
   "source": [
    "def process_abc_files(paths):\n",
    "    texts = []\n",
    "    for i in tqdm(paths):\n",
    "        if i.suffix != \".abc\":\n",
    "            continue\n",
    "\n",
    "        keys = []\n",
    "        notes = []\n",
    "        with open(i) as rf:\n",
    "            for line in rf:\n",
    "                line = line.strip()\n",
    "                if line.startswith(\"%\"):\n",
    "                    continue\n",
    "\n",
    "                if len(line) > 1 and line[0] in \"BCDFGHIKLMmNOPQRrSsTUVWwXZ\" and line[1] == \":\":\n",
    "                    keys.append(line)\n",
    "                else:\n",
    "                    notes.append(line)\n",
    "\n",
    "        text = \"\\n\".join(keys)\n",
    "        notes = \"\".join(notes)\n",
    "\n",
    "        if text.endswith(\"|\"):\n",
    "            text = text[:-1]\n",
    "\n",
    "\n",
    "        notes = notes.replace(\" \", \"\")\n",
    "        notes = notes.replace(\"[\", \" [\")\n",
    "        notes = notes.replace(\"]\", \"] \")\n",
    "        notes = notes.replace(\"(\", \" (\")\n",
    "        notes = notes.replace(\")\", \") \")\n",
    "        notes = notes.replace(\"|\", \" | \")\n",
    "        notes = notes.strip()\n",
    "        notes = notes.replace(\"  \", \" \")\n",
    "        \n",
    "        if not keys or not notes:\n",
    "            continue\n",
    "\n",
    "        text = text + \"\\n\" + notes + \"\\n\"\n",
    "        text = \" \".join(text.split(\" \"))     \n",
    "        texts.append(text)\n",
    "        \n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cellId": "ehwooic6lh7bm2418fibqi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 4249.78it/s]\n"
     ]
    }
   ],
   "source": [
    "train = process_abc_files(train_paths)[:100]\n",
    "# test = process_abc_files(test_paths)[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "eccun09jwzrbcbr9b8su4"
   },
   "source": [
    "## Make dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cellId": "w7t0tsj8cr57cb5bkey9i"
   },
   "outputs": [],
   "source": [
    "tokenizer = yttm.BPE(\"abc.yttm\", n_threads=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cellId": "txmn30q65ygvo07l2q86"
   },
   "outputs": [],
   "source": [
    "class ABCDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, \n",
    "                 context_bars_num=8, \n",
    "                 target_bars_num=1,\n",
    "                 is_test=False):\n",
    "        \n",
    "        self.notes = []\n",
    "        self.keys = []\n",
    "        for i, text in enumerate(texts):\n",
    "            if text.count(\"x8 | \"*3) != 0 and not is_test:\n",
    "                continue\n",
    "                print(i)\n",
    "            \n",
    "            try:\n",
    "                text = text.strip()\n",
    "                keys, notes = text.rsplit(\"\\n\", 1)\n",
    "                notes = notes.split(\" | \")\n",
    "            except Exception:\n",
    "                import pdb;pdb.set_trace()\n",
    "            \n",
    "            if len(notes) < context_bars_num + target_bars_num and not is_test:\n",
    "                continue\n",
    "                print(i)\n",
    "                \n",
    "            self.keys.append(keys)\n",
    "            self.notes.append(notes)\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.context_bars_num = context_bars_num\n",
    "        self.target_bars_num = target_bars_num\n",
    "        self.is_test = is_test\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        notes = self.notes[idx]\n",
    "        keys = self.keys[idx]\n",
    "        \n",
    "        if not self.is_test:\n",
    "            split_indx = random.randint(self.context_bars_num, len(notes) - self.target_bars_num)\n",
    "\n",
    "            context_notes = notes[split_indx - self.context_bars_num : split_indx]\n",
    "            target = notes[split_indx: split_indx + self.target_bars_num]\n",
    "        else:\n",
    "            context_notes = notes\n",
    "            target = []\n",
    "\n",
    "        context = keys + \"\\n\" + \" | \".join(context_notes).strip()\n",
    "        if not context.endswith(\"|\"):\n",
    "            context += \" | \"\n",
    "\n",
    "        target = \" | \".join(target)\n",
    "\n",
    "        context_tokens = self.tokenizer.encode(context, bos=True, eos=True)\n",
    "        target_tokens = self.tokenizer.encode(target, bos=True, eos=True)\n",
    "        \n",
    "        context_tokens = torch.tensor(context_tokens, dtype=torch.long)\n",
    "        target_tokens = torch.tensor(target_tokens, dtype=torch.long)\n",
    "\n",
    "        return {\"features\": context_tokens, \"target\": target_tokens}\n",
    "    \n",
    "    \n",
    "train_dataset = ABCDataset(train, tokenizer)\n",
    "# test_dataset = ABCDataset(test, tokenizer, is_test=True)\n",
    "\n",
    "\n",
    "def collate_function(batch):\n",
    "    features = [i[\"features\"] for i in batch]\n",
    "    target = [i[\"target\"] for i in batch]\n",
    "    \n",
    "    features_lens = [len(i) for i in features]\n",
    "    target_lens = [len(i) for i in target]\n",
    "    \n",
    "    max_features_len = max(features_lens)\n",
    "    max_target_len = max(target_lens)\n",
    "    \n",
    "    features_mask = torch.tensor([[1] * l + [0] * (max_features_len - l) for l in features_lens],\n",
    "                                 dtype=torch.bool)\n",
    "    \n",
    "    target_mask = torch.tensor([[1] * l + [0] * (max_target_len - l) for l in target_lens],\n",
    "                                dtype=torch.bool)\n",
    "    \n",
    "    features_padded = pad_sequence(features, batch_first=True)\n",
    "    target_padded = pad_sequence(target, batch_first=True)\n",
    "    \n",
    "    return {\"features\": features_padded, \"target\": target_padded, \n",
    "            \"features_mask\": features_mask, \"target_mask\": target_mask}\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_function)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True, collate_fn=collate_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "tivhlaypbkdpiga7gpxs1k"
   },
   "source": [
    "# Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "cellId": "bymdelxr543tuhreil6z"
   },
   "outputs": [],
   "source": [
    "config_encoder = BertConfig()\n",
    "config_decoder = BertConfig()\n",
    "\n",
    "config_encoder.vocab_size = tokenizer.vocab_size()\n",
    "config_decoder.vocab_size = tokenizer.vocab_size()\n",
    "config_decoder.is_decoder = True\n",
    "config_decoder.add_cross_attention = True\n",
    "\n",
    "config = EncoderDecoderConfig.from_encoder_decoder_configs(config_encoder, config_decoder)\n",
    "model = EncoderDecoderModel(config=config)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "bvpm8kxznkezstldrig6fi"
   },
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cellId": "ftposz543btfhemmo25r9"
   },
   "outputs": [],
   "source": [
    "loaders = {\n",
    "    \"train\": train_loader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "cellId": "xmgrrgpzz6rul21b4z6ns"
   },
   "outputs": [],
   "source": [
    "class CustomRunner(dl.Runner):\n",
    "    def _handle_batch(self, batch):\n",
    "        # model train/valid step\n",
    "        features = batch[\"features\"]\n",
    "        features_mask = batch[\"features_mask\"]\n",
    "        target = batch[\"target\"]\n",
    "        target_mask = batch[\"target_mask\"]\n",
    "        \n",
    "        output = model(input_ids=features, decoder_input_ids=target, labels=target,\n",
    "                       attention_mask=features_mask, decoder_attention_mask=target_mask)\n",
    "\n",
    "        self.batch_metrics.update(\n",
    "            {\"loss\": output.loss.cpu().item()}\n",
    "        )\n",
    "        if self.is_train_loader:\n",
    "            output.loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "cellId": "hnno5boellebyr58eh1g5l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1/5 * Epoch (train):   0% 0/2 [02:29<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "1/5 * Epoch (train):   0% 0/2 [13:22<?, ?it/s]\n",
      "1/5 * Epoch (train):   0% 0/2 [11:57<?, ?it/s]\n",
      "1/5 * Epoch (train):   0% 0/2 [07:29<?, ?it/s]\n",
      "1/5 * Epoch (train):   0% 0/2 [10:10<?, ?it/s]\n",
      "1/5 * Epoch (train):   0% 0/2 [03:06<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1/5 * Epoch (train):   0% 0/2 [01:14<?, ?it/s, loss=10.858]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1/5 * Epoch (train):  50% 1/2 [01:14<01:14, 74.22s/it, loss=10.858]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1/5 * Epoch (train):  50% 1/2 [01:55<01:14, 74.22s/it, loss=4.640] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1/5 * Epoch (train): 100% 2/2 [01:55<00:00, 64.22s/it, loss=4.640]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1/5 * Epoch (train): 100% 2/2 [01:55<00:00, 57.56s/it, loss=4.640]\n",
      "[2020-12-18 00:43:34,648] \n",
      "1/5 * Epoch 1 (train): loss=8.7004\n",
      "2/5 * Epoch (train): 100% 2/2 [02:03<00:00, 61.72s/it, loss=13.809]\n",
      "[2020-12-18 00:45:46,638] \n",
      "2/5 * Epoch 2 (train): loss=10.3554\n",
      "3/5 * Epoch (train): 100% 2/2 [03:37<00:00, 108.84s/it, loss=16.503]\n",
      "[2020-12-18 00:49:30,046] \n",
      "3/5 * Epoch 3 (train): loss=17.6497\n",
      "                                                                    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A                            Early exiting\n",
      "4/5 * Epoch (train):  50% 1/2 [04:56<03:35, 215.07s/it, loss=18.256]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1/5 * Epoch (train):   0% 0/2 [13:35<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "runner = CustomRunner()\n",
    "# model training\n",
    "runner.train(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    loaders=loaders,\n",
    "    logdir=\"./logs\",\n",
    "    num_epochs=5,\n",
    "    verbose=True,\n",
    "    load_best_on_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "2gspvx8dt8rsyrx31hcsy"
   },
   "source": [
    "# Generate melodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "cellId": "7373p21zau7peqgo60w00i"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10200/10200 [04:08<00:00, 41.06it/s]\n"
     ]
    }
   ],
   "source": [
    "z = model.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "x0zq771lwigmlx9wpcosk"
   },
   "source": [
    "# Submit midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "cellId": "ne0r1zyuotchwy2hensgo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m[Step 1/2]\u001b[0m Submitting audio files from ./predict_midi ...\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "Unexpected error has occurred during execution of your task. Please, try again or contact us via Support: https://console.cloud.yandex.ru/support",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "#!nirvana\n",
    "yadc_submit_results --result-dir ./predict_midi --user $user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "jofu9xzgj146284a3uv08"
   },
   "source": [
    "# Вспомогательные функции (уже загружены в состояние)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellId": "3ytq65r0rm6luljs5p1w2"
   },
   "outputs": [],
   "source": [
    "def download_file(url: str, local_filename: str = None) -> str:\n",
    "    local_filename = local_filename or url.split('/')[-1]\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        with open(local_filename, 'wb') as f:\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "    return local_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellId": "7ql29r72mdqvkn10m23ba"
   },
   "outputs": [],
   "source": [
    "def unzip(zip_filename: str, dst_dir: str = './'):\n",
    "    with zipfile.ZipFile(zip_filename, 'r') as zf:\n",
    "        for entry in tqdm(zf.infolist(), desc='Extracting '):\n",
    "            try:\n",
    "                zf.extract(entry, dst_dir)\n",
    "            except zipfile.error as e:\n",
    "                print(e)\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellId": "rauaihid285q4ka0t9mak"
   },
   "outputs": [],
   "source": [
    "def collect_children(path: Path) -> List[Path]:\n",
    "    if path.is_file():\n",
    "        return [path]\n",
    "    else:\n",
    "        result = []\n",
    "        for child in path.iterdir():\n",
    "            if child.is_file():\n",
    "                result.append(child)\n",
    "            elif child.is_dir():\n",
    "                result.extend(collect_children(child))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellId": "adcc7213xw4h7283rpfa1"
   },
   "outputs": [],
   "source": [
    "def read_abc(path: Path) -> List[List[str]]:\n",
    "    header = []\n",
    "    bars = []\n",
    "    is_header = True\n",
    "    with open(path, 'r') as input_file:\n",
    "        for line in input_file:\n",
    "            line = line.strip()\n",
    "            if is_header and (not line or line.startswith('%') or (line[0] in ascii_letters and line[1] == ':')):\n",
    "                header.append(line)\n",
    "            else:\n",
    "                is_header = False\n",
    "                bars.append(line)\n",
    "    return header, bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellId": "ibcnisihrzbhga630mve6"
   },
   "outputs": [],
   "source": [
    "def abc2midi(abc_file: Path, midi_file: Path) -> None:\n",
    "    command = f'abc2midi {abc_file} -o {midi_file}'\n",
    "    subprocess.run(command.split(), timeout=2, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellId": "ibl847hlzdo61vg3x65u0h"
   },
   "outputs": [],
   "source": [
    "def plot_pianoroll(path: Path, title: str = '') -> None:\n",
    "    ext = path.suffix\n",
    "    midi_file = path if ext == '.mid' else Path('tmp') / f'{path.stem}.mid'\n",
    "    if ext == '.abc' and not midi_file.is_file():\n",
    "        abc2midi(path, midi_file)\n",
    "    if midi_file.is_file():\n",
    "        music21.converter.parse(midi_file).plot('pianoroll', title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellId": "0q8icnj0djpm1h7nmtymvm"
   },
   "outputs": [],
   "source": [
    "def player(path: Path):\n",
    "    ext = path.suffix\n",
    "    wav_file = path if ext == '.wav' else Path('tmp') / f'{path.stem}.wav'\n",
    "    if ext == '.mid':\n",
    "        midi2wav(path, wav_file)\n",
    "    elif ext == '.abc':\n",
    "        midi_file = Path('tmp') / f'{path.stem}.mid'\n",
    "        abc2midi(path, midi_file)\n",
    "        midi2wav(midi_file, wav_file)\n",
    "    if wav_file.is_file():\n",
    "        return Audio(wav_file)\n",
    "    else:\n",
    "        print(f'could not convert {path} to .wav')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cellId": "pu0la1z7kkdrthxyjaj5m"
   },
   "outputs": [],
   "source": [
    "def midi2wav(midi_file: Path, wav_file: Path) -> None:\n",
    "    FluidSynth(sound_font='GeneralUser GS 1.471/GeneralUser GS v1.471.sf2', sample_rate=8000).midi_to_audio(midi_file, wav_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "wm4ygh7txgowu9v3a2feli"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "notebookId": "00a17ff7-a652-4ed9-a193-542eafa7199e"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
