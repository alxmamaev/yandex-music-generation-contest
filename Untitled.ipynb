{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import *\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig, EncoderDecoderConfig, EncoderDecoderModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = yttm.BPE(\"abc.yttm\")\n",
    "test_paths = get_training_files('testset/abc')\n",
    "test_texts = [read_abc(p) for p in test_paths]\n",
    "# test_set = ABCDataset(test_texts, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(tokenizer.vocab_size())\n",
    "checkpoint = torch.load(\"pytorch_model.bin\", map_location=\"cpu\")\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:1 T: M:4/4 L:1/8 Q:1/4=82 K:D V:1 @ A,,E,A,3/2x/2G,2E,3/2x/2 | E,,2xA,,/2- [B,,/2A,,/2] D,x/2D,/2A,,/2B,,/2D, | A,,E,A,2G,2E,3/2x/2 | E,/2E,/2E,/2E,/2 [D/2G,/2E,/2]  [D/2G,/2E,/2] D,/2E,/2x/2D,/2E,/2x/2 [D/2G,/2E,/2-]  [D/2G,/2E,/2-] E,/2x/2 | E,/2E,/2x/2x/2 [C/2G,/2E,/2]  [C/2G,/2E,/2] D,/2 [C3/2G,3/2E,3/2-] E,2-E,/2x/2 | E,/2E,/2E,/2E,/2 [D/2G,/2E,/2]  [D/2G,/2E,/2] D,/2E,/2x/2D,/2E,/2x/2 [D/2G,/2E,/2-]  [D/2G,/2E,/2-] E,/2x/2 | E,/2E,/2x/2x/2 [C/2G,/2E,/2]  [C/2G,/2E,/2] D,/2 [C3/2G,3/2E,3/2-] E,2-E,/2x/2 | G,/2x/2G,/2G,/2 [D/2G,/2E,/2]  [D/2G,/2E,/2] A,/2A,/2x/2G,/2A,/2x/2 [D/2A,/2G,/2-E,/2]  [D/2G,/2E,/2-] E,/2x/2\n"
     ]
    }
   ],
   "source": [
    "test_text = test_texts[5436]\n",
    "print(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys, notes = test_text.split(\" @ \")\n",
    "notes = notes.split(\" | \")\n",
    "\n",
    "gen_tokens = None\n",
    "context = keys + \"@\" + \" | \".join(notes)\n",
    "context_tokens = tokenizer.encode(context, bos=True, eos=True)\n",
    "input_tokens = torch.tensor(context_tokens, dtype=torch.long)\n",
    "\n",
    "gen_tokens = model.generate(input_ids=input_tokens.unsqueeze(0), \n",
    "                            max_length=350, \n",
    "                            num_beams=4,\n",
    "                            early_stopping=True,\n",
    "                            bos_token_id=2, \n",
    "                            eos_token_id=3, \n",
    "                            pad_token_id=0,\n",
    "                            top_k=None)[0].tolist()\n",
    "\n",
    "notes += tokenizer.decode(gen_tokens, ignore_ids=[0,1,2,3])[0].split(\" | \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,,E,A,3/2x/2G,2E,3/2x/2|\n",
      "E,,2xA,,/2-[B,,/2A,,/2]D,x/2D,/2A,,/2B,,/2D,|\n",
      "A,,E,A,2G,2E,3/2x/2|\n",
      "E,/2E,/2E,/2E,/2[D/2G,/2E,/2][D/2G,/2E,/2]D,/2E,/2x/2D,/2E,/2x/2[D/2G,/2E,/2-][D/2G,/2E,/2-]E,/2x/2|\n",
      "E,/2E,/2x/2x/2[C/2G,/2E,/2][C/2G,/2E,/2]D,/2[C3/2G,3/2E,3/2-]E,2-E,/2x/2|\n",
      "E,/2E,/2E,/2E,/2[D/2G,/2E,/2][D/2G,/2E,/2]D,/2E,/2x/2D,/2E,/2x/2[D/2G,/2E,/2-][D/2G,/2E,/2-]E,/2x/2|\n",
      "E,/2E,/2x/2x/2[C/2G,/2E,/2][C/2G,/2E,/2]D,/2[C3/2G,3/2E,3/2-]E,2-E,/2x/2|\n",
      "G,/2x/2G,/2G,/2[D/2G,/2E,/2][D/2G,/2E,/2]A,/2A,/2x/2G,/2A,/2x/2[D/2A,/2G,/2-E,/2][D/2G,/2E,/2-]E,/2x/2|\n",
      "E,/2E,/2x/2x/2[C/2G,/2E,/2][C/2G,/2E,/2]D,/2E,/2x/2[C3/2G,3/2E,3/2-]E,2-E,/2|\n",
      "E,/2E,/2E,/2E,/2E,/2[D/2G,/2E,/2][D/2G,/2E,/2]D,/2E,/2x/2[D/2G,/2E,/2-]E,2-E,/2|\n",
      "E,/2E,/2x/2x/2[C/2G,/2E,/2][C/2G,/2E,/2]D,/2E,/2x/2D,/2E,/2x/2[D/2G,/2E,/2-][D/2G,/2E,/2-]E,/2x/2|\n",
      "E,/2E,/2x/2x/2[C/2G,/2E,/2][C/2G,/2E,/2]D,/2E,/2x/2[C3/2G,3/2E,3/2-]E,2-E,/2|\n",
      "E,/2E,/2x/2x/2[D/2G,/2E,/2][D/2G,/2E,/2]D,/2E,/2x/2D,/2E,/2x/2[D/2G,/2E,/2-][D/2G,/2E,/2-]E,/2x/2|\n",
      "E,/2E,/2x/2x/2[C/2G,/2E,/2][C/2G,/2E,/2]D,/2E,/2x/2[C3/2G,3/2E,3/2-]E,2-E,/2|\n",
      "G,/2x/2G,/2G,/2[D/2G,/2E,/2][D/2G,/2E,/2]A,/2A,/2x/2G,/2A,/2x/2[D/2A,/2G,/2-E,/2][D/2G,/2E,/2-]E,/2x/2|\n",
      "E,/2E,/2x/2x/2[C/2G,/2E,/2][C/2G,/2E,/2]D,/2E,/2x/2[D/2G,/2E,/2-]E,2-E,/2x\n"
     ]
    }
   ],
   "source": [
    "print(\"|\\n\".join(notes).replace(\" \", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X:1 T: M:4/4 L:1/8 Q:1/4=115 K:D V:1'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(notes[-1].split(\"|\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
