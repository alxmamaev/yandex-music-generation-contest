{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import *\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig, EncoderDecoderConfig, EncoderDecoderModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = yttm.BPE(\"abc.yttm\")\n",
    "test_paths = get_training_files('trainset/abc')[:200]\n",
    "test_texts = [read_abc(p) for p in test_paths]\n",
    "test_dataset = ABCDataset(test_texts, tokenizer, is_test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<BOS> M:4/4 L:1/8 Q:1/4=60 K:G%1sharps @ [^D2-A,2-B,,2-] [^D/2-A,/2F,/2-B,,/2-] [^D-F,-B,,-] [^D/2-A,/2-F,/2B,,/2] [^D/2A,/2B,,/2-] [B3/2^D3/2A,3/2B,,3/2-] [F/2-^D/2-A,/2-F,/2-B,,/2-] [G/2-F/2^D/2-A,/2-F,/2B,,/2] [G/2^D/2A,/2-] A,/2 | [E3/2-=C3/2-C,,3/2-] [E/2-C/2-G,/2-C,,/2-] [E/2C/2-G,/2C,/2-C,,/2-] [G3/2C3/2-G,3/2C,3/2C,,3/2] [E2-C2-G,2-C,,2-] [E/2-C/2-G,/2C,/2-C,,/2-] [E/2C/2G,/2C,/2-C,,/2] C,/2- [E/2C/2G,/2C,/2] | [=D2-B,2-G,2-G,,2-] [D/2B,/2-G,/2D,/2-G,,/2-] [GB,-D,-G,,] [B,/2D,/2] [G/2B,/2-G,,/2-] [B,/2G,,/2-] [D/2^A,/2=A,/2G,,/2-] G,,/2- [D-A,-D,-G,,] [D/2A,/2-D,/2-] [A,/2G,/2D,/2] | [^C2-G,2A,,2-] [E3/2-^C3/2-E,3/2-A,,3/2] [E/2^C/2G,/2E,/2] [E3/2-^C3/2-A,,3/2-] [E/2-^C/2-G,/2-A,,/2-] [E/2-^C/2-G,/2E,/2-A,,/2-] [E/2-^C/2G,/2-E,/2-A,,/2-] [E/2-G,/2E,/2-A,,/2-] [E/2^C/2E,/2A,,/2] | [G3/2-D3/2-B,3/2-G,,3/2-] [G/2-D/2-B,/2-D,/2-G,,/2-] [G-D-B,G,-D,-G,,-] [G/2-D/2-G,/2-D,/2-G,,/2-] [G/2-D/2-B,/2-G,/2D,/2-G,,/2] [G/2-D/2-B,/2D,/2G,,/2-] [G-D-G,,-] [G/2-D/2-D,/2-G,,/2-] [G/2D/2-G,/2D,/2G,,/2] [D/2B,/2-] B,/2D/2 | x2G,3/2- [B,/2-G,/2] [B,/2G,,/2-] G,,3/2- [D,/2G,,/2] G,/2x | [^D2-A,2-B,,2-] [^D/2-A,/2F,/2-B,,/2-] [^D/2-A,/2F,/2-B,,/2-] [^D/2-F,/2-B,,/2] [^D/2-A,/2-F,/2] [^D-A,B,,-] [^D/2-B,,/2-] [^D/2A,/2-B,,/2-] [A,/2F,/2-B,,/2-] [F/2-^D/2-F,/2B,,/2] [F/2-^D/2-] [F/2^D/2] | [G/2-B,/2-E,,/2-] [G3/2-B,3/2-B,,3/2E,,3/2-] [G/2-B,/2-E,/2-E,,/2-] [G-B,-G,-E,E,,-] [G/2-B,/2-G,/2B,,/2E,,/2] [G-B,-E,,-] [G-B,-G,E,,-] [G/2-B,/2-E,/2-E,,/2] [GB,G,E,-] E,/2 |<EOS>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(test_dataset[4][\"features\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<BOS> [E-C-G,C,,-] [E/2-C/2-C,,/2-] [E/2-C/2-G,/2-C,,/2-] [E/2C/2-G,/2C,/2-C,,/2-] [GC-G,C,-C,,] [E/2C/2C,/2] [E-C-G,C,,-] [E/2-C/2-C,,/2-] [E/2-C/2-G,/2-C,,/2-] [E/2C/2G,/2C,/2-C,,/2] [GCG,C,-] [D/2C,/2] | [D3/2-B,3/2-G,3/2G,,3/2-] [D/2-B,/2-G,,/2-] [D/2B,/2-D,/2-G,,/2-] [B,-G,D,-G,,] [D/2B,/2D,/2] G,,/2- [d/2-D/2-D,/2G,,/2-] [d/2D/2G,,/2-] [A/2-G,/2-G,,/2-] [d/2-A/2-D/2-G,/2-G,,/2] [d/2-A/2D/2-G,/2-G,,/2-] [d/2D/2-G,/2-G,,/2-] [G/2D/2G,/2G,,/2] | [G-DC,-] [G/2-C,/2-] [G/2E/2C,/2] [G3/2-C3/2-C,,3/2-] [G/2-C/2-G,/2-C,,/2-] [G/2-C/2-G,/2C,/2-C,,/2-] [G/2-C/2-G,/2C,/2-C,,/2-] [G/2C/2C,/2-C,,/2] [G,/2C,/2] [D/2^A,/2=A,/2C,,/2-] [A,/2-C,,/2-] [D/2A,/2C,,/2] [G,/2C,/2] | [D-G,G,,-] [D/2-G,,/2-] [D/2-G,/2G,,/2-] [G/2-D/2G,/2D,/2-G,,/2-] [G-CD,-G,,-] [G/2-B,/2-D,/2G,,/2] [G/2-B,/2G,/2-G,,/2-] [G/2-G,/2-G,,/2-] [G/2D/2-G,/2-G,,/2-] [D/2G,/2G,,/2-] [G/2-B,/2-D,/2-G,,/2-] [G/2-B,/2-G,/2-D,/2-G,,/2] [G/2B,/2G,/2-D,/2-] [D/2G,/2D,/2] | [E-^CG,A,,-] [E/2A,,/2-] A,,/2- [E-^C-G,E,-A,,-] [E/2-^C/2-E,/2-A,,/2] [E/2-^C/2-G,/2-E,/2] [E/2^C/2-G,/2A,,/2-] [^C/2G,/2-A,,/2-] [G,/2A,,/2-] [^C/2A,,/2-] [E/2-^C/2-E,/2-A,,/2-] [E/2^C/2-G,/2-E,/2-A,,/2-] [^C/2-G,/2E,/2-A,,/2-] [E/2^C/2E,/2A,,/2] | [^F-D-A,D,,-] [F/2-D/2-D,,/2-] [F/2-D/2-A,/2-D,,/2-] [F/2D/2A,/2D,/2-D,,/2-] [AD-A,D,D,,] [F/2D/2A,,/2] [F/2-D/2-A,/2D,,/2-] [F/2-D/2-A,/2A,,/2-D,,/2-] [F/2D/2-A,,/2D,,/2-] [D/2A,/2D,/2-D,,/2-] [F/2-D/2-A,/2D,/2-D,,/2-] [F/2D/2A,/2D,/2A,,/2-D,,/2-] [A,,/2D,,/2] [F/2D/2A,/2] | x2D,>G, [G2-D2-B,2-] [G/2-D/2B,/2-G,,/2-] [G/2B,/2G,/2-G,,/2] G,/2B,/2 | [^D2-A,2-B,,2-] [^D/2-A,/2F,/2-B,,/2-] [^D/2-A,/2F,/2-B,,/2-] [^D/2-F,/2-B,,/2-] [^D/2-A,/2-F,/2B,,/2] [^D3/2-A,3/2B,,3/2-] [^D/2A,/2B,,/2-] [F-^D-A,F,B,,] [F/2^D/2-] [^D/2A,/2] |<EOS>']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(test_dataset[4][\"target\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(tokenizer.vocab_size())\n",
    "checkpoint = torch.load(\"pytorch_model.bin\", map_location=\"cpu\")\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model.load_state_dict(checkpoint)\n",
    "\n",
    "# checkpoint = torch.load(\"pytorch_model-2.bin\", map_location=\"cpu\")\n",
    "\n",
    "# config_encoder = BertConfig()\n",
    "# config_decoder = BertConfig()\n",
    "\n",
    "# config_encoder.vocab_size = tokenizer.vocab_size()\n",
    "# config_decoder.vocab_size = tokenizer.vocab_size()\n",
    "# config_decoder.is_decoder = True\n",
    "# config_decoder.add_cross_attention = True\n",
    "\n",
    "# config = EncoderDecoderConfig.from_encoder_decoder_configs(config_encoder, config_decoder)\n",
    "# model = EncoderDecoderModel(config=config)\n",
    "# model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = test_dataset[0][\"features\"].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<BOS> M:4/4 L:1/8 Q:1/4=50 K:D%2sharps @ [=C3/2A,3/2^D,3/2F,,3/2] [^A,E,G,,] [=A,E,A,,] [^G,-=D,^A,,-] [^G,/2E,/2-^A,,/2] E,/2 [=A,=F,A,,] [^C=G,E,A,,] [D/2-=F,/2-D,/2-D,,/2-] | [D/2=F,/2D,/2D,,/2] x [A^F] [AF] [A3/2F3/2] [G/2E/2] [FD] [EA,] [D/2-F,/2-] | [D3/2F,3/2] [GDB,] [BDG,] [ADF,] x/2x/2 [GE] [F/2D/2] x/2 [A/2E/2-C/2-A,/2] | [E/2C/2] x [A3/2F3/2] [G/2E/2] [FDD,-] [F/2-D/2-D,/2] [F/2D/2] [EC-G,-^A,,-] [ECG,^A,,] [D/2-B,/2-F,/2-B,,/2-] | [D/2B,/2F,/2B,,/2] xd [d=A=F,] [d^GE,] [cEA,] [B^FDD,] [A/2D/2-B,/2-E,/2-] [^G/2F/2D/2B,/2E,/2] [A/2-^G/2C/2-A,/2-A,,/2-] | [A/2C/2A,/2A,,/2] x [AF] [AF] [A3/2F3/2] [=G/2E/2] [FD] [EA,] [D/2-F,/2-] | [DF,] x/2 [GDB,] [BDG,] [ADF,] x/2x/2 [G/2E/2] [A/2A,/2] [F/2-D/2-] [F/2D/2] [E/2-C/2-] | [E/2C/2] x [A3/2F3/2] [G/2E/2] [FDD,-] [FDD,] [EC-G,-^A,,-] [ECG,^A,,] [D/2-B,/2-F,/2-B,,/2-] |<EOS>']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_ids.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_text = model.generate(input_ids=input_ids, max_length=500,\n",
    "                          bos_token_id=2, eos_token_id=3, pad_token_id=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS><BOS>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(gen_text.tolist()[1:-1])[0].replace(\" \", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: ['<BOS> [FCA,F,C,F,,]2B,2G,2] [D/2-F,/2-] [EE,]c/2B/2- [E3-B, [G/2D/2A,/2D,/2]D/2-B,/2-G,/2-G,,/2-] [F/2-F,,/2-]-G,-G,,]3/2F,3/2C,3/2F,,3/2] [FF,,]4-G,4-E,,4-] [G-B,-G,3/2B,3/2-B,,3/2-]C,,,/2 [A/2^G/2 [ecGC,,] [G/2F/2E/2 [AFB,]-d-A [a/2D,/2-]6-F,6-] [d/2D/2-] [F3/2-D3/2A,3/2-]3-=G,,3-] [A/2-A,/2-] [B^D [g/2E,,/2]-E,-B,,] [f/2F/24-_G [G/2D/2B,/2G,/23/2G,,,3/2-]EAA,/2D,/2-A,,/2-] [F3-_D a/2x/2 [E/2C/2A,/2A,,/2A,,,/2]']\n",
      "1: ['<BOS> [FCA,F,C,F,,]2B,2G,2] [D/2-F,/2-] [EE,]c/2B/2- [E3-B, [G/2D/2A,/2D,/2]D/2-B,/2-G,/2-G,,/2-] [F/2-F,,/2-]-G,-G,,]3/2F,3/2C,3/2F,,3/2] [FF,,]4-G,4-E,,4-] [G-B,-G,3/2B,3/2-B,,3/2-]C,,,/2 [A/2^G/2 [ecGC,,] [G/2F/2E/2 [AFB,]-d-A [a/2D,/2-]6-F,6-] [d/2D/2-] [F3/2-D3/2A,3/2-]3-=G,,3-] [A/2-A,/2-] [B^D [g/2E,,/2]-E,-B,,] [f/2F/24-_G [G/2D/2B,/2G,/23/2G,,,3/2-]EAA,/2D,/2-A,,/2-] [F3-_D a/2x/2G/2']\n",
      "2: ['<BOS> [FCA,F,C,F,,]2B,2G,2] [D/2-F,/2-] [EE,]c/2B/2- [E3-B, [G/2D/2A,/2D,/2]D/2-B,/2-G,/2-G,,/2-] [F/2-F,,/2-]-G,-G,,]3/2F,3/2C,3/2F,,3/2] [FF,,]4-G,4-E,,4-] [G-B,-G,3/2B,3/2-B,,3/2-]C,,,/2 [A/2^G/2 [ecGC,,] [G/2F/2E/2 [AFB,]-d-A [a/2D,/2-]6-F,6-] [d/2D/2-] [F3/2-D3/2A,3/2-]3-=G,,3-] [A/2-A,/2-] [B^D [g/2E,,/2]-E,-B,,] [f/2F/24-_G [G/2D/2B,/2G,/23/2G,,,3/2-]EAA,/2D,/2-A,,/2-] [F3-_D a/2x/22D,2-]']\n",
      "3: ['<BOS> [FCA,F,C,F,,]2B,2G,2] [D/2-F,/2-] [EE,]c/2B/2- [E3-B, [G/2D/2A,/2D,/2]D/2-B,/2-G,/2-G,,/2-] [F/2-F,,/2-]-G,-G,,]3/2F,3/2C,3/2F,,3/2] [FF,,]4-G,4-E,,4-] [G-B,-G,3/2B,3/2-B,,3/2-]C,,,/2 [A/2^G/2 [ecGC,,] [G/2F/2E/2 [AFB,]-d-A [a/2D,/2-]6-F,6-] [d/2D/2-] [F3/2-D3/2A,3/2-]3-=G,,3-] [A/2-A,/2-] [B^D [g/2E,,/2]-E,-B,,] [f/2F/24-_G [G/2D/2B,/2G,/23/2G,,,3/2-]EAA,/2D,/2-A,,/2-] [F3-_De/2x/2e4f']\n",
      "4: ['<BOS> [FCA,F,C,F,,]2B,2G,2] [D/2-F,/2-] [EE,]c/2B/2- [E3-B, [G/2D/2A,/2D,/2]D/2-B,/2-G,/2-G,,/2-] [F/2-F,,/2-]-G,-G,,]3/2F,3/2C,3/2F,,3/2] [FF,,]4-G,4-E,,4-] [G-B,-G,3/2B,3/2-B,,3/2-]C,,,/2 [A/2^G/2 [ecGC,,] [G/2F/2E/2 [AFB,]-d-A [a/2D,/2-]6-F,6-] [d/2D/2-] [F3/2-D3/2A,3/2-]3-=G,,3-] [A/2-A,/2-] [B^D [g/2E,,/2]-E,-B,,] [f/2F/24-_G [G/2D/2B,/2G,/23/2G,,,3/2-]EA [G2E2C2B,2]=C,=F,,] A3-=B,,,/2]']\n"
     ]
    }
   ],
   "source": [
    "beam_outputs = model.generate(\n",
    "    input_ids, \n",
    "    max_length=40, \n",
    "    num_beams=5, \n",
    "    no_repeat_ngram_size=1, \n",
    "    num_return_sequences=5, \n",
    "    early_stopping=True,\n",
    "    temperature=0.7,\n",
    "    bos_token_id=2, eos_token_id=3, pad_token_id=0\n",
    ")\n",
    "\n",
    "# now we have 3 output sequences\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "for i, beam_output in enumerate(beam_outputs):\n",
    "    print(\"{}: {}\".format(i, tokenizer.decode(beam_output.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<BOS> [FCA,F,C,F,,]2B,2G,2] [D/2-F,/2-] [EE,]c/2B/2- [E3-B, [G/2D/2A,/2D,/2]D/2-B,/2-G,/2-G,,/2-] [F/2-F,,/2-]-G,-G,,]3/2F,3/2C,3/2F,,3/2] [FF,,]4-G,4-E,,4-] [G-B,-G,3/2B,3/2-B,,3/2-]C,,,/2 [A/2^G/2 [ecGC,,] [G/2F/2E/2 [AFB,]-d-A [a/2D,/2-]6-F,6-] [d/2D/2-] [F3/2-D3/2A,3/2-]3-=G,,3-] [A/2-A,/2-] [B^D [g/2E,,/2]-E,-B,,] [f/2F/24-_G [G/2D/2B,/2G,/23/2G,,,3/2-]EAA,/2D,/2-A,,/2-] [F3-_D a/2x/2 [E/2C/2A,/2A,,/2A,,,/2]'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'<BOS> [FCA,F,C,F,,]2B,2G,2] [D/2-F,/2-] [EE,]c/2B/2- [E3-B, [G/2D/2A,/2D,/2]D/2-B,/2-G,/2-G,,/2-] [F/2-F,,/2-]-G,-G,,]3/2F,3/2C,3/2F,,3/2] [FF,,]4-G,4-E,,4-] [G-B,-G,3/2B,3/2-B,,3/2-]C,,,/2 [A/2^G/2 [ecGC,,] [G/2F/2E/2 [AFB,]-d-A [a/2D,/2-]6-F,6-] [d/2D/2-] [F3/2-D3/2A,3/2-]3-=G,,3-] [A/2-A,/2-] [B^D [g/2E,,/2]-E,-B,,] [f/2F/24-_G [G/2D/2B,/2G,/23/2G,,,3/2-]EAA,/2D,/2-A,,/2-] [F3-_D a/2x/2 [E/2C/2A,/2A,,/2A,,,/2]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
